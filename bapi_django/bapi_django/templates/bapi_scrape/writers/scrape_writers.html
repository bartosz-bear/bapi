{% extends "base.html" %}   // Inherits all the components from base template, including the header and footer

{% block main %}

<main>

  <div class="reading">

    <h2 id="movies-swap">Scraping writers</h2><br>

    <p>'best_movies' spider, scraping from live <a href='https://www.quotes.toscrape.com' target="_blank" rel="noopener">quotes.toscrape.com</a>. 83 quotes from 10
       different pages. Deals with pagination and JavaScript, dynamically generated content using splash.
       </p>

       <div class="box">

       {% load static %}
       <img src="{% static 'bapi_scrape/writers.png' %}" class="box.img" alt="Best movies"><br><br>

      </div><br>

       <p>Data is saved to SQL database and it can be viewed in the Expose section: <a href='/expose/expose_writers/'>Scraped writers data</a><br><br></p>
       

       <h2>Crawler code</h2>

       <p>Below you can see the code for the crawler. Alternatively you can see in the GitHub repo.</p>

    <pre><code class="language-python">
import scrapy
from scrapy_splash import SplashRequest

class WritersSpider(scrapy.Spider):
    name = "writers"
    allowed_domains = ["quotes.toscrape.com"]

    script = '''
      function main(splash, args)
        --splash.private_mode_enabled = false
        url = args.url
        assert(splash:go(url))
        assert(splash:wait(1))
        --rur_tab = assert(splash:select_all(".filterPanelItem___2z5Gb"))
        --rur_tab[5]:mouse_click()
        --assert(splash:wait(1))
        splash:set_viewport_full()
      return {
          --image = splash:png(), -- show a png image of the website
          html = splash:html() -- show the html of the website
        }
      end
              '''
    
    custom_settings = {'ITEM_PIPELINES': {
        'imdb.pipelines.WritersPipeline': 300
    }}

    def start_requests(self):
        yield SplashRequest(url="http://quotes.toscrape.com/js",
                            callback=self.parse,
                            endpoint="execute",
                            args={'lua_source': self.script})

    def parse(self, response):
        
      
        divs = response.xpath('//div[@class="quote"]')


        for i, d in enumerate(divs):
          quote = d.xpath('.//span[@class="text"]/text()').get()
          author = d.xpath('.//small[@class="author"]/text()').get()
          tag_holder = d.xpath('.//div[@class="tags"]')
          tags = tag_holder.xpath('.//a[@class="tag"]/text()').getall()

          yield {'quote': quote,
              'author': author,
              'tags': tags}
          
        
        next_page = response.xpath("//li[@class='next']/a/@href").get()

        if next_page:
            next_page = "http://quotes.toscrape.com" + next_page
            yield SplashRequest(url=next_page,
                            callback=self.parse,
                            endpoint="execute",
                            args={'lua_source': self.script})

    </code></pre>

  </div>

</main>

{% load static %}

<script src="https://unpkg.com/htmx.org@1.8.6"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/vs2015.min.css">
<script>hljs.highlightAll();</script>

{% endblock %}

{% block style %}

<style>
  body {
    background: white;
  }
  .box {
    width: 100%;
    height: 100%;
    border: 1px solid white;
    display: flex;
    justify-content: center;
  }
  img {
    width: 80%;
    height: 100%;
    margin: 0 auto;
  }

  .table {
    table-layout:fixed;
  }

  .table th {
    color: white;
  }

  .table td {
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
  }
  div.reading {
    width: 800px;
    margin: 0 auto;
  }

  #myProgress {
    width: 100%;
    background-color: #ddd;
  }

  #myBar {
    width: 1%;
    height: 30px;
    background-color: #04AA6D;
  }
</style>

{% endblock %}
